\section{Data Preview 0}\label{sec:dp0}

In \citeds{LSO-011} we outlined a number of scenarios for early releases of \RO~data. The purpose of the these releases are not only to prepare the community for LSST data, but also to serve as an early integration test of existing elements of the Data Management systems and to familiarize the community with our access mechanisms.

Two major new developments have occurred since \citeds{LSO-011} was drafted:

\begin{itemize}

\item There have since been delays in construction such that we are now planning on making Data Previews with \RO~simulated data or on-sky data from other observatories (see \secref{sec:dataset}) which would still allow us to meet some of the goals of the early releases.

\item We are planning on carrying these activities at the Intermediate Data Facility, which is is dedicated to Pre-Ops activities infrastructure needs such as serving data and training operations staff. (Commissioning actives will continue at NCSA and in Chile.)

\end{itemize}

In this document we outline notable elements of DP0, the first of these planned data previews, from the Data Management and Pre-Operations perspective.

\section{Elements of Data Preview 0}

% PJM: Is this section only about DP0.1, serving catalog data from pre-processed images? I think we need to explain the different phases of DP0 at the start, when we show the milestones. And then conisder the dataset options in that context, eg it could be a different mix of data in DP0.1 from DP0.2. Note that a DP0.3 is also possible, given the time available in FY22.

In this section we discuss the following key topics:

\begin{itemize}

\item Dataset choice considerations

\item Data products offered

\item Services offered

\item Audience considerations

\end{itemize}

\subsection {Dataset choice considerations} \label{sec:dataset}

The Construction Project has been working for some time now with a number of pre-cursor datasets and simulated data. There are two leading candidates for forming the basis of DP0:

\begin{itemize}

\item The Subaru Hyper Suprime-Cam PDR2 dataset, provided permission can be secured from our HSC colleagues. As real (on-sky) data it is likely that users will interact with it in more realistic ways. It is a well understood dataset, and it is regularly re-processed with software that shares a common codebase with the LSST Science Pipelines.

\item The simulated precursor to LSST data produced by the Dark Energy Survey, DESC DC2, provided permission can be secured. This is a very large dataset and putting DC2 catalogs in Qserv would be an excellent demonstration of its abilities.

\end{itemize}

There is interest from the science collaborations in working with data products from both of these datasets. DC2 was emphasized at the 2019 PCW, and at least one (AGN) has contributed to the simulation inputs since then. A comment at the PCW discussion was that without DC2 in DP0, the science collaborations would not see full frame LSST data until the year before the survey, too late for the needed analysis development.
% PJM: to re-live the PCW2019 session, see the slide deck at https://docs.google.com/presentation/d/1tRHdSyXBRp850zfJO5NssHS-fGfGMMngDEfAD9Azdk4/edit#slide=id.g5e4570c6eb_0_10 and the notes at https://docs.google.com/document/d/1fSNwsT12hTQGZsH--C6sIY58k6ODHx4vnsPfQa82t9Q/edit#heading=h.8o7p552v6klp 

Data Management is currently in transition between its 2nd and 3rd generation data abstraction layer (aka ``Butler''). For DP0 to fulfill its aim as an early deployment/integration exercise, Gen 3 Butler must be used, preferably (stretch goal) using an S3 compliant Object Store as is the intent in production. This has bearing on the choice of dataset.

HSC PDR2 can either be converted from Gen 2 to Gen 3 or (stretch goal but ideally) reprocessed naively with Gen3. A smaller subset may be necessary to avoid production scaling issues. This is the preferred choice in the short term from an engineering point of view.

DC2 is available through Gen2 Butler and as we do not process that data with the Science Pipelines, the only option is conversion to Gen3. Estimates are that this is such a time-consuming process that it cannot be done in time to meet milestone XXX. Therefore if DC2 is to be involved in the short term, a significantly smaller subset would have to be selected.

Questions:

\begin{itemize}

\item Which dataset has the broader scientific interest? This question could be answered via a community survey: indeed, the possibility of such a survey was discussed at the 2019 PCW.

\item For either dataset if we take a subset to avoid the Gen2-Gen3 conversion issues or production scaling issues, will that reduce the usefulness of the datasets or affect the choice? What would be the smallest data size that is still scientifically interesting?

\item Will we be able to do Butler over S3 and Postgres at production grade by DP0?

\item Given the delayed construction/commissioning schedule, could we consider including both of these datasets in DP0 over the course of FY21--FY22?

\end{itemize}

\subsection{Data Products Offered}

We will offer access to images and catalogs, though in more limited ways that will be available in Operations.

Images will be stored in read-only Butler Gen3 repo.

Catalogues will be stored in Qserv.

We may provide images and catalogs from different production runs based on the same dataset.

Questions:

\begin{itemize}

\item Are we offering parquet files? --- No promise. Currently our SDMified parquet-generating pipelines are HSC only and Gen2 only.

\item We should presumably explicitly rule out bulk download  --- YES. However, this ({\it was} discussed at the 2019 PCW, as a potential mitigation against there not being batch compute available in DP0. If a particular group requested bulk download, it could be an opportunity to start developing that capability. We will also need to know whether to allow DESC bulk download access as part of the MOU to gain access to DC2: they may well want to download all the re-processed products, for their own purposes (and to develop their capability to ingest and work with bulk downloads).

\item When does ingest into Qserv has to start to be ready by DP0?

\end{itemize}

\subsection{Services Offered}

Although DP0 as a milestone described \citeds{LSO-011} can be fulfilled with simple data distribution, we intend to offer limited Science Platform functionality as part of DP0. This includes:

\begin{itemize}

\item Provided the data is stored in Qserv or a Postgres database, catalogue access through TAP

\item Access to the Science Platform's notebook-based analysis environment (Nublado); images can be accessed pragmatically via the Butler.

\item Federated Authentication

\end{itemize}

Shell access (except through Nublado) will not be offered.

Questions:

\begin{itemize}

\item Is it understood that portal is not included? Not necessarily ..

\end{itemize}


\subsection{Audience Considerations}

Care should be taken to limit the target audience for the data previews; it is most critical that this is done for DP0.

\begin{itemize}

\item We have limited capacity to divert resources to support users.

\item We will not have performed scaling tests on the Science Platform services by that point; current Science Platform usage is under 100 users, and any intent to exceed that should be communicated well in advance

\item We will not yet have the ability to throttle excessive IDF usage

\end{itemize}

Authorization will be provided in an all-in basis (users will have the same level of access as project members currently have) since finer access control mechanisms will not be available by DP0; care should be taken in selecting them.

Questions:

\begin{itemize}

\item What is the authorization constraints for this data? For example, are DC2 data products only available to DESC science collaboration members? If so, if DC2 is chosen, does only DESC participate in DP0?
	{\bf No: When agreed, DC2 would be available to all data rights holders.}

\item How do we handle access? First come first served? Do we need a sign-up process?

\item How do we intend to do support? Slack? JIRA? CLO?

\end{itemize}

\section{DP0.2 - processing}

The Milestone DP-SP-02 includes re processing on IDF of the data set previously served as part of DP-SP-01.
This requires a workflow system and associated tools to preferable make this quite automated.
Demonstrating a portable set of cloud enabled tools based on Butler Gen 3 and HTCondor would help to allay the main risk of moving to a new Data Facility in operations.

\section{Risks and mitigation}

The biggest schedule risk is not getting an interim data facility in place in time.
This would delay the entire schedule and there is not much mitigation.

In the long run costs may be higher than expected in a cloud based IDF. This will be due to storage.
An mitigation to this would be to store data on our own systems (NCSA or Chile) and expose it through S3.
NCSA already have this in place and we should consider testing this for lesser used data sets.
