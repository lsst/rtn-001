\tiny \begin{longtable} {|l|p{0.1\textwidth}|p{0.1\textwidth}|p{0.35\textwidth}|l|l|l|} \caption{Team members for Data Production for Rubin Observatory  FY21 \label{tab:teamsNames}}\\ 
\hline 
\textbf{WBS}&\textbf{Team}&\textbf{Role Title}&\textbf{Role Description}&\textbf{Institution}&\textbf{FY21 FTE}&\textbf{Staff} \\ \hline
{3.1a}&{Data Production Management}&{Associate Director for Data Production}&{The AD of the Data Production Department is one of the principal leaders of the Rubin Observatory operations phase. This position requires a Ph.D. level astronomer with extensive astronomical survey and science management experience, and reports directly to the Rubin Observatory Director. The primary responsibilities of this position include the management of the Data Production Department, participation in the leadership of Rubin Observatory survey, and coordination with other Rubin Observatory Departments. The AD for Data Production also has overall responsibility and authority for safely running the Rubin Observatory Data Facilities (LDF) including the generation of prompt data products (alerts) and the annual data release processing. This person will supervise a technical staff that will be responsible for all aspects of data processing, preparation of data products, archiving, and operation of the Chilean, French and other DACs, as well as the US LDF. They will be responsible for coordinating with project level Contract Management and Supplier Management when dealing with issues of business impact, and accountable for ensuring a disaster recovery plan is effective and able to be invoked. The AD of Data Production is also responsible for supervising the data flow from the Recinto to the LDF.}&{AURA}&{0.50}&{O'Mullane, William} \\ \hline
{3.1c}&{Data Production Management}&{Data Production Advisor - US DF}&{Each Rubin Observatory Data Facility (currently USA and France) have an advisory role to the AD for Data Production in terms of execution across the data facilities.  }&{NCSA}&{0.35}&{Butler, Michelle} \\ \hline
{3.1d}&{Data Production Management}&{Data Production Advisor - IN2P3}&{Each Rubin Observatory Data Facility (currently USA and France) have and advisory role to the AD for Data Production in terms of execution across the data facilities. This has both a logistic and managerial element - there are local dtaff to manage but we need the entire organisation to work for prociessing. }&{IN2P3}&{0.25}&{Fabio Hernandez} \\ \hline
{3.2j}&{Infrastructure and Support}&{IT Network Engineer - US DF}&{Provides network hardware and operational functionality used from a site's border router to Rubin Observatory end equipment. Collaborates with the security engineer and also IT services related to dynamic reallocation of US DF enclaves to support these functions with network features. Supplies higher-level network services as needed at each site, such as DNS, NTP, domain name registrations, netflows, and support for security.}&{NCSA}&{0.25}&{Kollross, Matt} \\ \hline
{3.2k}&{Infrastructure and Support}&{Wide Area Network Technical Manager}&{Responsible for providing coordination amongst and managing relationships with the four independent WAN operators. Acts as the interface for services provided to the US DF in the context of the WAN. Responsible for managing the risk associated with each WAN operator, including developing mitigation strategies and proposed project responses to credible risks. Leads the Joint Wide Area Network Working Group. Well connected to DOE ESNet.}&{Fermilab}&{0.38}&{Demar, Phil} \\ \hline
{3.2l}&{Infrastructure and Support}&{Wide Area Network Architect}&{Familiar with WAN implementation technologies generally available in the networks supporting the Rubin Observatory. Familiar with technology roadmap of the ESNet WAN provider. Synthesizes and evolves network techniques and provisioning supporting the Rubin Observatory mission, as network technology evolves. Drawn from staff of WAN groups but explicitly supported by and work in the context of the Rubin Observatory.}&{Fermilab}&{0.38}&{Bobyshev, Andrey} \\ \hline
{3.2r}&{Infrastructure and Support}&{Data Wrangler - IN2P3}&{The data wrangler ensures that data (science raw data, calibration data, data products, etc.) is replicated at IN2P3 and data products resulting from the local processing performed at IN2P3 are replicated to the USDF They also ensure that the data archived at IN2P3 and needed for the annual processing are recalled from tape on time for the image processing tasks to be performed. They ensure that the tools and systems used for replicating data at IN2P3 are operational. This role needs tight coordination with the team at the USDF that is responsible for data distribution.}&{IN2P3}&{0.35}&{Bastien Gounon} \\ \hline
{3.2r}&{Infrastructure and Support}&{Data Wrangler - IN2P3}&{The data wrangler ensures that data (science raw data, calibration data, data products, etc.) is replicated at IN2P3 and data products resulting from the local processing performed at IN2P3 are replicated to the USDF They also ensure that the data archived at IN2P3 and needed for the annual processing are recalled from tape on time for the image processing tasks to be performed. They ensure that the tools and systems used for replicating data at IN2P3 are operational. This role needs tight coordination with the team at the USDF that is responsible for data distribution.}&{IN2P3}&{0.25}&{Fabio Hernandez} \\ \hline
{3.2s}&{Infrastructure and Support}&{Image Handler - IN2P3}&{The image handler ensures the image processing stages assigned to IN2P3 are performed on time. This person also ensures that the processing (e.g. software releases, configuration files, etc.) is compatible with what is agreed upon with the other processing sites, in particular with the USDF. They also ensure that IN2P3's image processing infrastructure (batch processing, workflow management system, etc.) is operational and correctly configured for LSST needs. They also ensure the day-to-day operations of the annual image processing campaign. This role needs tight coordination with the team in charge of image processing at the USDF.}&{IN2P3}&{0.25}&{Bastien Gounon} \\ \hline
{3.2s}&{Infrastructure and Support}&{Image Handler - IN2P3}&{The image handler ensures the image processing stages assigned to IN2P3 are performed on time. This person also ensures that the processing (e.g. software releases, configuration files, etc.) is compatible with what is agreed upon with the other processing sites, in particular with the USDF. They also ensure that IN2P3's image processing infrastructure (batch processing, workflow management system, etc.) is operational and correctly configured for LSST needs. They also ensure the day-to-day operations of the annual image processing campaign. This role needs tight coordination with the team in charge of image processing at the USDF.}&{IN2P3}&{0.20}&{Fabio Hernandez} \\ \hline
{3.2t}&{Infrastructure and Support}&{Catalog Manager - IN2P3}&{The catalog manager ensures the day-to-day operations of the astronomical catalog database at IN2P3. This includes ingesting new data and removing and archiving obsolete catalogs. They also interact with the data wrangler to ensure that the catalog data produced at other sites are imported and ingested into the IN2P3 catalog and that the catalog data produced at IN2P3 is ingested into the local catalog and replicated to other sites. They also ensure that the software releases for the catalog database are compatible with those releases used at other sites operating a catalog database, in particular, the USDF.}&{IN2P3}&{0.15}&{Bastien Gounon} \\ \hline
{3.2t}&{Infrastructure and Support}&{Catalog Manager - IN2P3}&{The catalog manager ensures the day-to-day operations of the astronomical catalog database at IN2P3. This includes ingesting new data and removing and archiving obsolete catalogs. They also interact with the data wrangler to ensure that the catalog data produced at other sites are imported and ingested into the IN2P3 catalog and that the catalog data produced at IN2P3 is ingested into the local catalog and replicated to other sites. They also ensure that the software releases for the catalog database are compatible with those releases used at other sites operating a catalog database, in particular, the USDF.}&{IN2P3}&{0.15}&{Fabrice James} \\ \hline
{3.3a}&{Science Users Middleware}&{Middleware Lead}&{Organizes the software maintenance effort and assigns work in a way that provides for continuity of maintenance for all Rubin Observatory maintained software. Is primarily responsible for further defining and enforcing software engineering rules related to maintenance, including maintenance of documentation, correct security practices, testing, and other aspects of delivery of a complete change set. Ensures that software tasks are consistent with authorized changes. Carries share of maintenance load. Participates in reviews.}&{AURA}&{0.25}&{Jenness, Tim} \\ \hline
{3.3b}&{Science Users Middleware}&{Database Engineer (Qserv) - SLAC}&{Develops, maintains, and implements the science Databases e.g. QSERV database, data butler, Prompt Products Database. May also work on other middleware as needed.}&{SLAC}&{0.75}&{Mueller, Fritz} \\ \hline
{3.3b}&{Science Users Middleware}&{Database Engineer (Qserv) - SLAC}&{Develops, maintains, and implements the science Databases e.g. QSERV database, data butler, Prompt Products Database. May also work on other middleware as needed.}&{SLAC}&{0.75}&{Gaponenko, Igor} \\ \hline
{3.3b}&{Science Users Middleware}&{Database Engineer (Qserv) - SLAC}&{Develops, maintains, and implements the science Databases e.g. QSERV database, data butler, Prompt Products Database. May also work on other middleware as needed.}&{SLAC}&{0.75}&{Pease, Nate} \\ \hline
{3.3c}&{Science Users Middleware}&{Service Software Engineer - SLAC}&{Develops, maintains, and implements DF software, including:  Data Butler, Alert Filtering Service, orchestration software, workflow software, data backbone software, integration testing framework, authentication services, pipeline construction tools, operational fabric codes, logging, messaging, monitoring and health and status software, hosting environment for Rubin Observatory Data Space, Data Space batching services, and bulk export to other sites.}&{SLAC}&{0.75}&{Gates, John} \\ \hline
{3.3c}&{Science Users Middleware}&{Service Software Engineer - SLAC}&{Develops, maintains, and implements DF software, including:  Data Butler, Alert Filtering Service, orchestration software, workflow software, data backbone software, integration testing framework, authentication services, pipeline construction tools, operational fabric codes, logging, messaging, monitoring and health and status software, hosting environment for Rubin Observatory Data Space, Data Space batching services, and bulk export to other sites.}&{SLAC}&{0.25}&{Hanushevsky, Andy} \\ \hline
{3.3c}&{Science Users Middleware}&{Service Software Engineer - SLAC}&{Develops, maintains, and implements DF software, including:  Data Butler, Alert Filtering Service, orchestration software, workflow software, data backbone software, integration testing framework, authentication services, pipeline construction tools, operational fabric codes, logging, messaging, monitoring and health and status software, hosting environment for Rubin Observatory Data Space, Data Space batching services, and bulk export to other sites.}&{SLAC}&{0.25}&{Salnikov, Andy} \\ \hline
{3.3c}&{Science Users Middleware}&{Service Software Engineer - SLAC}&{Develops, maintains, and implements DF software, including:  Data Butler, Alert Filtering Service, orchestration software, workflow software, data backbone software, integration testing framework, authentication services, pipeline construction tools, operational fabric codes, logging, messaging, monitoring and health and status software, hosting environment for Rubin Observatory Data Space, Data Space batching services, and bulk export to other sites.}&{BNL}&{0.13}&{Strecker-Kellogg, Will} \\ \hline
{3.3c}&{Science Users Middleware}&{Service Software Engineer - SLAC}&{Develops, maintains, and implements DF software, including:  Data Butler, Alert Filtering Service, orchestration software, workflow software, data backbone software, integration testing framework, authentication services, pipeline construction tools, operational fabric codes, logging, messaging, monitoring and health and status software, hosting environment for Rubin Observatory Data Space, Data Space batching services, and bulk export to other sites.}&{BNL}&{0.25}&{Strecker-Kellogg, Will} \\ \hline
{3.3c}&{Science Users Middleware}&{Service Software Engineer - SLAC}&{Develops, maintains, and implements DF software, including:  Data Butler, Alert Filtering Service, orchestration software, workflow software, data backbone software, integration testing framework, authentication services, pipeline construction tools, operational fabric codes, logging, messaging, monitoring and health and status software, hosting environment for Rubin Observatory Data Space, Data Space batching services, and bulk export to other sites.}&{BNL}&{0.13}&{Padolski, Sergey} \\ \hline
{3.3c}&{Science Users Middleware}&{Service Software Engineer - SLAC}&{Develops, maintains, and implements DF software, including:  Data Butler, Alert Filtering Service, orchestration software, workflow software, data backbone software, integration testing framework, authentication services, pipeline construction tools, operational fabric codes, logging, messaging, monitoring and health and status software, hosting environment for Rubin Observatory Data Space, Data Space batching services, and bulk export to other sites.}&{BNL}&{0.25}&{Padolski, Sergey} \\ \hline
{3.3d}&{Science Users Middleware}&{Data Management Software Engineer - SLAC}&{Maintain Rucio system which will be involved in the tracking and moving of data between multiple sites. This is in close conjunction with the Storage Engineers in the Data Facilities. Rucio is an open source HEP product which we have adopted on Rubin Observatory. }&{Fermilab}&{0.70}&{White, Brandon} \\ \hline
{3.3e}&{Science Users Middleware}&{Dev/ Ops Software Engineer - US DF}&{Maintain and improve the batch processing and data backbone services at the US DF. As we enter operations a set of tools (Pegasus, Condor, GPFS, Rucio) are used and some glue (middleware) sits between them to make the systems work. As these are upgraded the glue will need to be reshaped.}&{AURA}&{0.25}&{Chiang, Hsin-Fang} \\ \hline
{3.3e}&{Science Users Middleware}&{Dev/ Ops Software Engineer - US DF}&{Maintain and improve the batch processing and data backbone services at the US DF. As we enter operations a set of tools (Pegasus, Condor, GPFS, Rucio) are used and some glue (middleware) sits between them to make the systems work. As these are upgraded the glue will need to be reshaped.}&{NCSA}&{0.30}&{Gower, Michelle} \\ \hline
{3.3e}&{Science Users Middleware}&{Dev/ Ops Software Engineer - US DF}&{Maintain and improve the batch processing and data backbone services at the US DF. As we enter operations a set of tools (Pegasus, Condor, GPFS, Rucio) are used and some glue (middleware) sits between them to make the systems work. As these are upgraded the glue will need to be reshaped.}&{NCSA}&{0.25}&{Kowlik, Nic} \\ \hline
{3.3g}&{Science Users Middleware}&{Dev/ Ops Software Engineer - IN2P3}&{Develops, maintains, and implements DF software, including: QSERV database, data butler, DAX, Alert Filtering Service, orchestration software, workflow software, data backbone software, integration testing framework, authentication services, pipeline construction tools, operational fabric codes, logging, messaging, monitoring and health and status software, hosting environment for Rubin Observatory Data Space, Data Space batching services, and bulk export to other sites.}&{IN2P3}&{0.20}&{Fabrice James} \\ \hline
{3.3g}&{Science Users Middleware}&{Dev/ Ops Software Engineer - IN2P3}&{Develops, maintains, and implements DF software, including: QSERV database, data butler, DAX, Alert Filtering Service, orchestration software, workflow software, data backbone software, integration testing framework, authentication services, pipeline construction tools, operational fabric codes, logging, messaging, monitoring and health and status software, hosting environment for Rubin Observatory Data Space, Data Space batching services, and bulk export to other sites.}&{IN2P3}&{0.20}&{Sabine Elles} \\ \hline
{3.4a}&{Execution}&{Lead Production Scientist - US DF}&{Responsible for leading the Execution Team. This includes responsibility for managing the activities of the team members, planning work, and reporting on progress and issues to the next level of management. Additionally, the Lead Production Scientist must possess all of the skills and qualifications of a Production Scientist.}&{NCSA}&{0.50}&{Gruendl, Robert} \\ \hline
{3.4b}&{Execution}&{Production Scientist - US DF}&{Responsible for processing and database ingestion of Prompt (Alert) and Batch (Annual Data Release) Data Products. This includes responsibility for: acting as the Scientific Code Liaison, hardware and software deployment, oversight and responsibility for processing execution, prompt SDQA and response, alert filtering service operations, and external (community) broker operations.}&{NCSA}&{0.25}&{Adamow, Monika } \\ \hline
{3.4c}&{Execution}&{Production Scientist - SLAC}&{Responsible for processing and database ingestion of Prompt (Alert) and Batch (Annual Data Release) Data Products. This includes responsibility for: acting as the Scientific Code Liaison, hardware and software deployment, oversight and responsibility for processing execution, prompt SDQA and response, alert filtering service operations, and external (community) broker operations.}&{Fermilab}&{0.25}&{Yanny, Brian} \\ \hline
{3.4c}&{Execution}&{Production Scientist - SLAC}&{Responsible for processing and database ingestion of Prompt (Alert) and Batch (Annual Data Release) Data Products. This includes responsibility for: acting as the Scientific Code Liaison, hardware and software deployment, oversight and responsibility for processing execution, prompt SDQA and response, alert filtering service operations, and external (community) broker operations.}&{Fermilab}&{0.25}&{Lin, Huan} \\ \hline
{3.4e}&{Execution}&{Computation Facility Scientist - SLAC}&{Improve performance of the Data Production codes on the specific hardware of the day. This means improving computational performance and data throughput of the different pipelines. This spans all parts of the software and fits well in the middleware team, between all parts of the system.}&{Fermilab}&{0.25}&{Kuropatkin, Nikolay} \\ \hline
{3.4e}&{Execution}&{Computation Facility Scientist - SLAC}&{Improve performance of the Data Production codes on the specific hardware of the day. This means improving computational performance and data throughput of the different pipelines. This spans all parts of the software and fits well in the middleware team, between all parts of the system.}&{Fermilab}&{0.10}&{Tucker, Douglas} \\ \hline
{3.4e}&{Execution}&{Computation Facility Scientist - SLAC}&{Improve performance of the Data Production codes on the specific hardware of the day. This means improving computational performance and data throughput of the different pipelines. This spans all parts of the software and fits well in the middleware team, between all parts of the system.}&{Fermilab}&{0.15}&{Neilsen, Eric} \\ \hline
{3.4f}&{Execution}&{Computation Facility Scientist - IN2P3}&{Improve performance of the Data Production codes on the specific hardware of the day. This means improving computational performance and data throughput of the different pipelines. This spans all parts of the software and fits well in the middleware team, between all parts of the system.}&{IN2P3}&{0.70}&{Dominique Boutigny} \\ \hline
{3.4h}&{Execution}&{Workload Manager - US DF}&{Provides workload management service (a batch service and data access methods upon a hardware cluster provided by the ITC function). This work is resident at the US Rubin Observatory Data Facility and used to provision the various clusters with uniform provisioning and administrative methods. Interfaces with security policy to ensure access by authorized users and supports workflows deployed on the system and data transfers to and from the corresponding batch system.}&{US DF}&{0.25}& \\ \hline
{3.4i}&{Execution}&{Environment Manager - US DF}&{Maintains data management policy/ environment for release builds/ computation/ distribution. }&{US DF}&{0.25}& \\ \hline
{3.5a}&{Algorithms and Pipelines}&{Lead of Algorithms and Pipelines}&{Responsible for the leadership and coordination of the Algorithms and Pipelines Team, the scientific integrity of Alert Production and Data Releases, and interaction and coordination with the Lead Community Scientist, Lead Scheduler Scientist, and the Lead Production Scientist.  This position requires a Ph.D. level astronomer with extensive astronomical survey and software experience, or a software engineer with extensive astronomical experience.}&{Princeton}&{0.25}&{Alsayyad, Yusra} \\ \hline
{3.5b}&{Algorithms and Pipelines}&{Alert Production Pipeline Group Leader}&{Applying extensive astronomical knowledge, including solar system, explosive transients, and time-domain surveys in general, and Rubin Observatory software experience, this role acts as product owner for the prompt processing pipelines and oversees the day-to-day work of the Alert Production Pipeline Scientists. Recommends changes to Alert Production Pipelines, and provides support to accept or reject software changes based on a scientific validation of new algorithms and an understanding of their impact on required computational resources. This position requires a Ph.D. level astronomer with extensive astronomical survey and software experience, or a software engineer with extensive astronomical experience.}&{UW}&{0.25}&{Bellm, Eric} \\ \hline
{3.5c}&{Algorithms and Pipelines}&{Alert Production Pipeline Scientist - NOIRLab}&{This role combines an understanding of one or more specific prompt processing science use cases with software engineering expertise and an understanding of the Rubin Observatory Science Pipelines to work in conjunction with the Science Software Engineering Group to modify, extend, and update the Prompt Processing Pipelines in response to emergent scientific needs, community requests, and bug reports. This role requires a Ph.D. level astronomer with extensive time-domain survey and software development experience, or a software engineer with extensive astronomical experience. Reports to the Alert Production Pipeline Group Leader.}&{UW}&{0.25}&{Sullivan, Ian} \\ \hline
{3.5c}&{Algorithms and Pipelines}&{Alert Production Pipeline Scientist - NOIRLab}&{This role combines an understanding of one or more specific prompt processing science use cases with software engineering expertise and an understanding of the Rubin Observatory Science Pipelines to work in conjunction with the Science Software Engineering Group to modify, extend, and update the Prompt Processing Pipelines in response to emergent scientific needs, community requests, and bug reports. This role requires a Ph.D. level astronomer with extensive time-domain survey and software development experience, or a software engineer with extensive astronomical experience. Reports to the Alert Production Pipeline Group Leader.}&{UW}&{0.25}&{Morrison, Chris} \\ \hline
{3.5c}&{Algorithms and Pipelines}&{Alert Production Pipeline Scientist - NOIRLab}&{This role combines an understanding of one or more specific prompt processing science use cases with software engineering expertise and an understanding of the Rubin Observatory Science Pipelines to work in conjunction with the Science Software Engineering Group to modify, extend, and update the Prompt Processing Pipelines in response to emergent scientific needs, community requests, and bug reports. This role requires a Ph.D. level astronomer with extensive time-domain survey and software development experience, or a software engineer with extensive astronomical experience. Reports to the Alert Production Pipeline Group Leader.}&{UW}&{0.25}&{Parejko, John} \\ \hline
{3.5d}&{Algorithms and Pipelines}&{Alert Production Pipeline Scientist - SLAC}&{This role combines an understanding of one or more specific prompt processing science use cases with software engineering expertise and an understanding of the Rubin Observatory Science Pipelines to work in conjunction with the Science Software Engineering Group to modify, extend, and update the Prompt Processing Pipelines in response to emergent scientific needs, community requests, and bug reports. This role requires a Ph.D. level astronomer with extensive time-domain survey and software development experience, or a software engineer with extensive astronomical experience. Reports to the Alert Production Pipeline Group Leader.}&{Fermilab}&{0.50}&{Herner, Ken} \\ \hline
{3.5d}&{Algorithms and Pipelines}&{Alert Production Pipeline Scientist - SLAC}&{This role combines an understanding of one or more specific prompt processing science use cases with software engineering expertise and an understanding of the Rubin Observatory Science Pipelines to work in conjunction with the Science Software Engineering Group to modify, extend, and update the Prompt Processing Pipelines in response to emergent scientific needs, community requests, and bug reports. This role requires a Ph.D. level astronomer with extensive time-domain survey and software development experience, or a software engineer with extensive astronomical experience. Reports to the Alert Production Pipeline Group Leader.}&{SLAC}&{0.50}&{Rasmussen, Andy} \\ \hline
{3.5e}&{Algorithms and Pipelines}&{Data Release Pipeline Group Leader}&{Applying extensive astronomical knowledge of all key Rubin Observatory science cases, including dark energy, galaxies, and stars; and of wide-field astronomical surveys in general, and Rubin Observatory software experience, this role acts as product owner for the data release processing pipelines and oversees the day-to-day work of the Data Release Pipeline Scientists. Recommends changes to Data Release Production Pipelines, and provides support to accept or reject software changes based on a scientific validation of new algorithms and an understanding of their impact on required computational resources. This position requires a Ph.D. level astronomer with extensive astronomical survey and software experience, or a software engineer with extensive astronomical experience.}&{Princeton}&{0.25}&{AlSayyad, Yusra} \\ \hline
{3.5f}&{Algorithms and Pipelines}&{Data Release Pipeline Scientist - NOIRLab}&{This role combines an understanding of one or more specific data release processing processing science use cases with software engineering expertise and an understanding of the Rubin Observatory Science Pipelines to work in conjunction with the Science Software Engineering Group to modify, extend, and update the Data Release Pipelines in response to emergent scientific needs, community requests, and bug reports. This role requires a Ph.D. level astronomer with extensive astronomical survey and software development experience, or a software engineer with extensive astronomical experience. Reports to the Data Release Pipeline Group Leader.}&{Princeton}&{0.25}&{Saunders, Clare} \\ \hline
{3.5f}&{Algorithms and Pipelines}&{Data Release Pipeline Scientist - NOIRLab}&{This role combines an understanding of one or more specific data release processing processing science use cases with software engineering expertise and an understanding of the Rubin Observatory Science Pipelines to work in conjunction with the Science Software Engineering Group to modify, extend, and update the Data Release Pipelines in response to emergent scientific needs, community requests, and bug reports. This role requires a Ph.D. level astronomer with extensive astronomical survey and software development experience, or a software engineer with extensive astronomical experience. Reports to the Data Release Pipeline Group Leader.}&{Princeton}&{0.25}&{Waters, Chris} \\ \hline
{3.5f}&{Algorithms and Pipelines}&{Data Release Pipeline Scientist - NOIRLab}&{This role combines an understanding of one or more specific data release processing processing science use cases with software engineering expertise and an understanding of the Rubin Observatory Science Pipelines to work in conjunction with the Science Software Engineering Group to modify, extend, and update the Data Release Pipelines in response to emergent scientific needs, community requests, and bug reports. This role requires a Ph.D. level astronomer with extensive astronomical survey and software development experience, or a software engineer with extensive astronomical experience. Reports to the Data Release Pipeline Group Leader.}&{Princeton}&{0.25}&{Taranu, Dan} \\ \hline
{3.5f}&{Algorithms and Pipelines}&{Data Release Pipeline Scientist - NOIRLab}&{This role combines an understanding of one or more specific data release processing processing science use cases with software engineering expertise and an understanding of the Rubin Observatory Science Pipelines to work in conjunction with the Science Software Engineering Group to modify, extend, and update the Data Release Pipelines in response to emergent scientific needs, community requests, and bug reports. This role requires a Ph.D. level astronomer with extensive astronomical survey and software development experience, or a software engineer with extensive astronomical experience. Reports to the Data Release Pipeline Group Leader.}&{Princeton}&{0.25}&{Kannawadi, Arun} \\ \hline
{3.5g}&{Algorithms and Pipelines}&{Data Release Pipeline Scientist - SLAC}&{This role combines an understanding of one or more specific data release processing processing science use cases with software engineering expertise and an understanding of the Rubin Observatory Science Pipelines to work in conjunction with the Science Software Engineering Group to modify, extend, and update the Data Release Pipelines in response to emergent scientific needs, community requests, and bug reports. This role requires a Ph.D. level astronomer with extensive astronomical survey and software development experience, or a software engineer with extensive astronomical experience. Reports to the Data Release Pipeline Group Leader.}&{SLAC}&{0.50}&{Myers, Josh} \\ \hline
{3.5g}&{Algorithms and Pipelines}&{Data Release Pipeline Scientist - SLAC}&{This role combines an understanding of one or more specific data release processing processing science use cases with software engineering expertise and an understanding of the Rubin Observatory Science Pipelines to work in conjunction with the Science Software Engineering Group to modify, extend, and update the Data Release Pipelines in response to emergent scientific needs, community requests, and bug reports. This role requires a Ph.D. level astronomer with extensive astronomical survey and software development experience, or a software engineer with extensive astronomical experience. Reports to the Data Release Pipeline Group Leader.}&{SLAC}&{0.50}& \\ \hline
{3.5h}&{Algorithms and Pipelines}&{Lead Calibration Scientist}&{Together with the Calibration Support Scientist at the summit, ensures that data is available to enable proper astrometric and photometric calibration of Rubin Observatory data as part of regular pipeline processing. The Lead Calibration Scientist reports to the Lead of the Algorithms and Pipelines Team. The Lead Calibration Scientist position requires a Ph.D. level astronomer with extensive astronomical survey and Rubin Observatory software experience: it is desirable for this position to be filled by a person who contributed to the construction of the Calibration Products Production pipeline.}&{D4D Ltd}&{0.25}&{Fisher-Levine, Merlin} \\ \hline
{3.5i}&{Algorithms and Pipelines}&{Lead Science Software Engineer}&{Defines, develops and maintains the overall architecture of the Rubin Observatory scientific processing pipelines, and provides advice and to the Pipeline and Calibration Scientists to ensure that the overall Rubin Observatory Science Pipelines form a coherent whole. Provides leadership to the Science Software Engineering Group, and reports to the Lead of Algorithms and Pipelines. Requires an expert in software architecture with extensive expertise in scientific software design in general and in the Rubin Observatory software system in particular.}&{Universities}&{0.25}&{Jim Bosch} \\ \hline
{3.5j}&{Algorithms and Pipelines}&{Science Software Engineers - NOIRLab}&{Provides software engineering support to the Alert Production, Data Release, and Calibration Groups. Works with the pipeline scientists on general code development, to help keep code maintainable and optimized, and reports to the Lead Science Software Engineer.}&{Princeton}&{0.25}&{Lust, Nate} \\ \hline
{3.5k}&{Algorithms and Pipelines}&{Science Software Engineer - SLAC}&{Provides software engineering support to the Alert Production, Data Release, and Calibration Groups. Works with the pipeline scientists on general code development, to help keep code maintainable and optimized, and reports to the Lead Science Software Engineer.}&{SLAC}&{0.50}&{Wittgen, Matthias} \\ \hline
{3.5l}&{Algorithms and Pipelines}&{Science Software Consultant}&{Supports and reports to the Lead Science Software Engineer. The Science Software Consultant position is a senior software position filled by fractions of individuals with deep and intimate knowledge of the Rubin Observatory Data Management system, presumably from the construction period.}&{Princeton}&{0.25}&{Lupton, Robert} \\ \hline
{3.6a}&{Science Platform and Reliability Engineering}&{Technical Lead/ Manager}&{Responsible for technical leadership and management of the Science Platform and Reliability Engineering Team. This includes   running stand ups and looking after budgets and staff issues as well as making technical calls where decisions are needed. }&{AURA}&{0.50}&{Economou, Frossie} \\ \hline
{3.6b}&{Science Platform and Reliability Engineering}&{DevOps Infrastructure Engineer - NOIRLab}&{Generalist software engineers who work through the entire software stack. A DevOps engineer must be able to understand the software and infrastructure enough to know it is working well. They must also be able to improve the infrastructure and debug problems which can span hardware, network and operating system all the way to the end user delivered service. }&{AURA}&{0.25}&{Sick, Jonathan} \\ \hline
{3.6b}&{Science Platform and Reliability Engineering}&{DevOps Infrastructure Engineer - NOIRLab}&{Generalist software engineers who work through the entire software stack. A DevOps engineer must be able to understand the software and infrastructure enough to know it is working well. They must also be able to improve the infrastructure and debug problems which can span hardware, network and operating system all the way to the end user delivered service. }&{AURA}&{0.25}&{Allbery, Russ} \\ \hline
{3.6b}&{Science Platform and Reliability Engineering}&{DevOps Infrastructure Engineer - NOIRLab}&{Generalist software engineers who work through the entire software stack. A DevOps engineer must be able to understand the software and infrastructure enough to know it is working well. They must also be able to improve the infrastructure and debug problems which can span hardware, network and operating system all the way to the end user delivered service. }&{NCSA}&{0.25}&{Long, Matt} \\ \hline
{3.6b}&{Science Platform and Reliability Engineering}&{DevOps Infrastructure Engineer - NOIRLab}&{Generalist software engineers who work through the entire software stack. A DevOps engineer must be able to understand the software and infrastructure enough to know it is working well. They must also be able to improve the infrastructure and debug problems which can span hardware, network and operating system all the way to the end user delivered service. }&{contractor}&{0.20}&{Basney, Jim} \\ \hline
{3.6c}&{Science Platform and Reliability Engineering}&{DevOps Infrastructure Engineer - US DF}&{Generalist software engineers who work through the entire software stack. A DevOps engineer must be able to understand the software and infrastructure enough to know it is working well. They must also be able to improve the infrastructure and debug problems which can span hardware, network and operating system all the way to the end user delivered service.  At least one of these engineers will have special competence in cybersecurity issues, and will ensure that Data Production services are developed and managed in accordance with Rubin Observatory cybersecurity policy.}&{US DF}&{0.38}& \\ \hline
{3.6c}&{Science Platform and Reliability Engineering}&{DevOps Infrastructure Engineer - US DF}&{Generalist software engineers who work through the entire software stack. A DevOps engineer must be able to understand the software and infrastructure enough to know it is working well. They must also be able to improve the infrastructure and debug problems which can span hardware, network and operating system all the way to the end user delivered service.  At least one of these engineers will have special competence in cybersecurity issues, and will ensure that Data Production services are developed and managed in accordance with Rubin Observatory cybersecurity policy.}&{US DF}&{0.38}& \\ \hline
{3.6d}&{Science Platform and Reliability Engineering}&{Science Platform Engineer}&{Maintains and develops the Science Platform (User Services) software [e.g. Jupyter notebooks, etc].}&{AURA}&{0.25}&{Banek, Christine} \\ \hline
{3.6d}&{Science Platform and Reliability Engineering}&{Science Platform Engineer}&{Maintains and develops the Science Platform (User Services) software [e.g. Jupyter notebooks, etc].}&{AURA}&{0.25}&{Thornton, Adam} \\ \hline
{3.6e}&{Science Platform and Reliability Engineering}&{Data Exploration Developer}&{Communicates data exploration needs to the engineers, documents and develops tools, demonstrates how to achieve scientific goals with the tools provided. This would explicitly include technical support to the Community and EPO scientists. These are specialist software engineers with science backgrounds who can cater to the scientific needs of the users.}&{AURA}&{0.25}&{Krughoff, Simon} \\ \hline
{3.6e}&{Science Platform and Reliability Engineering}&{Data Exploration Developer}&{Communicates data exploration needs to the engineers, documents and develops tools, demonstrates how to achieve scientific goals with the tools provided. This would explicitly include technical support to the Community and EPO scientists. These are specialist software engineers with science backgrounds who can cater to the scientific needs of the users.}&{AURA}&{0.25}&{Fausti, Angelo} \\ \hline
{3.6f}&{Science Platform and Reliability Engineering}&{Data Visualization Engineer}&{Documents and develops data visualization tools, demonstrates how to achieve scientific goals with the tools provided, produces example visualizations. Includes technical support in data visualization to the Community and EPO scientists. These are specialist software engineers with science backgrounds who can cater to the scientific needs of the users.}&{SLAC}&{0.25}&{Kaehler, Ralf} \\ \hline
\end{longtable} \normalsize
